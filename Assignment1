import pandas as pd
import os

try:
    # Load the dataset
    print("Loading dataset...")
    data = pd.read_csv('morg-2014-emp.csv')
    print(f"Dataset loaded successfully. Shape: {data.shape}")
    
    # Filter for legal occupations (codes 2100-2160)
    legal_data = data[(data['occ2012'] >= 2100) & (data['occ2012'] <= 2160)]
    print(f"Legal occupations data extracted: {legal_data.shape[0]} rows")
    
    if legal_data.shape[0] > 0:
        # Calculate earnings per hour
        legal_data['earnhre'] = legal_data['earnwke'] / legal_data['uhours']
        
        # Save to CSV file
        output_file = 'legal_occupations_filtered.csv'
        legal_data.to_csv(output_file, index=False)
        print(f"Data successfully saved to {output_file}")
    else:
        print("No legal occupation data found with codes 2100-2160")
        
except Exception as e:
    print(f"Error: {e}")


# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
import statsmodels.api as sm
from math import sqrt

# Load the dataset
data = pd.read_csv('legal_occupations_filtered.csv')

# Create earnings per hour variable
data['earnhre'] = data['earnwke'] / data['uhours']

# Data preprocessing
data = data.dropna(subset=['earnhre'])
data = data[data['earnhre'] > 0]

# Create predictive features
data['female'] = (data['sex'] == 2).astype(int)

# Map education to years
education_mapping = {
    31: 0, 32: 2.5, 33: 5.5, 34: 7.5, 35: 9, 36: 10, 37: 11, 38: 12, 
    39: 12, 40: 13, 41: 14, 42: 14, 43: 16, 44: 18, 45: 20, 46: 21
}
data['educ_years'] = data['grade92'].map(education_mapping)

# Create experience variables
data['exp'] = data['age'] - data['educ_years'] - 6
data['exp'] = data['exp'].clip(lower=0)
data['exp2'] = data['exp'] ** 2

# Create additional dummy variables
data['married'] = (data['marital'] == 1).astype(int)
data['white'] = (data['race'] == 1).astype(int)
data['black'] = (data['race'] == 2).astype(int)

# Handle outliers
q1 = data['earnhre'].quantile(0.25)
q3 = data['earnhre'].quantile(0.75)
iqr = q3 - q1
upper_bound = q3 + 1.5 * iqr
data_filtered = data[data['earnhre'] <= upper_bound].copy()



# Set target variable
y = data_filtered['earnhre']

# Define models with increasing complexity
X1 = data_filtered[['female', 'age']]
X2 = data_filtered[['female', 'age', 'educ_years']]
X3 = data_filtered[['female', 'age', 'educ_years', 'exp', 'white', 'black']]
X4 = data_filtered[['female', 'age', 'educ_years', 'exp', 'exp2', 'white', 'black', 'married']]

# Function to evaluate models
def evaluate_model(X, y, model_name):
    # Add constant term
    X_const = sm.add_constant(X)
    
    # Fit OLS model
    model = sm.OLS(y, X_const).fit()
    
    # Print model summary
    print(f"\n{model_name} Summary:")
    print(model.summary())
    
    # Full sample RMSE
    y_pred = model.predict(X_const)
    rmse = sqrt(mean_squared_error(y, y_pred))
    
    # BIC
    bic = model.bic
    
    # Cross-validation RMSE
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_rmse_scores = []
    
    for train_idx, test_idx in kf.split(X):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        
        X_train_const = sm.add_constant(X_train)
        model_cv = sm.OLS(y_train, X_train_const).fit()
        
        X_test_const = sm.add_constant(X_test)
        y_pred_cv = model_cv.predict(X_test_const)
        
        rmse_cv = sqrt(mean_squared_error(y_test, y_pred_cv))
        cv_rmse_scores.append(rmse_cv)
    
    cv_rmse = np.mean(cv_rmse_scores)
    
    return {
        'Model': model_name,
        'Variables': len(X.columns),
        'RMSE': rmse,
        'CV_RMSE': cv_rmse,
        'BIC': bic,
        'R-squared': model.rsquared
    }

# Evaluate all models
model1_results = evaluate_model(X1, y, "Model 1")
model2_results = evaluate_model(X2, y, "Model 2")
model3_results = evaluate_model(X3, y, "Model 3")
model4_results = evaluate_model(X4, y, "Model 4")

# Collect results
results_df = pd.DataFrame([
    model1_results, model2_results, model3_results, model4_results
])

print("\nModel Comparison:")
print(results_df)
